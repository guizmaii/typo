/**
 * File automatically generated by `typo` for its own test suite.
 *
 * IF YOU CHANGE THIS FILE YOUR CHANGES WILL BE OVERWRITTEN
 */
package testdb
package postgres
package pg_catalog

import anorm.RowParser
import anorm.Success
import java.time.ZonedDateTime
import play.api.libs.json.JsObject
import play.api.libs.json.JsResult
import play.api.libs.json.JsValue
import play.api.libs.json.Json
import play.api.libs.json.OFormat
import scala.util.Try

case class PgStatSysTablesRow(
  relid: Option[/* oid */ Long],
  schemaname: Option[String],
  relname: Option[String],
  seqScan: Option[Long],
  seqTupRead: Option[Long],
  idxScan: Option[Long],
  idxTupFetch: Option[Long],
  nTupIns: Option[Long],
  nTupUpd: Option[Long],
  nTupDel: Option[Long],
  nTupHotUpd: Option[Long],
  nLiveTup: Option[Long],
  nDeadTup: Option[Long],
  nModSinceAnalyze: Option[Long],
  nInsSinceVacuum: Option[Long],
  lastVacuum: Option[ZonedDateTime],
  lastAutovacuum: Option[ZonedDateTime],
  lastAnalyze: Option[ZonedDateTime],
  lastAutoanalyze: Option[ZonedDateTime],
  vacuumCount: Option[Long],
  autovacuumCount: Option[Long],
  analyzeCount: Option[Long],
  autoanalyzeCount: Option[Long]
)

object PgStatSysTablesRow {
  def rowParser(prefix: String): RowParser[PgStatSysTablesRow] = { row =>
    Success(
      PgStatSysTablesRow(
        relid = row[Option[/* oid */ Long]](prefix + "relid"),
        schemaname = row[Option[String]](prefix + "schemaname"),
        relname = row[Option[String]](prefix + "relname"),
        seqScan = row[Option[Long]](prefix + "seq_scan"),
        seqTupRead = row[Option[Long]](prefix + "seq_tup_read"),
        idxScan = row[Option[Long]](prefix + "idx_scan"),
        idxTupFetch = row[Option[Long]](prefix + "idx_tup_fetch"),
        nTupIns = row[Option[Long]](prefix + "n_tup_ins"),
        nTupUpd = row[Option[Long]](prefix + "n_tup_upd"),
        nTupDel = row[Option[Long]](prefix + "n_tup_del"),
        nTupHotUpd = row[Option[Long]](prefix + "n_tup_hot_upd"),
        nLiveTup = row[Option[Long]](prefix + "n_live_tup"),
        nDeadTup = row[Option[Long]](prefix + "n_dead_tup"),
        nModSinceAnalyze = row[Option[Long]](prefix + "n_mod_since_analyze"),
        nInsSinceVacuum = row[Option[Long]](prefix + "n_ins_since_vacuum"),
        lastVacuum = row[Option[ZonedDateTime]](prefix + "last_vacuum"),
        lastAutovacuum = row[Option[ZonedDateTime]](prefix + "last_autovacuum"),
        lastAnalyze = row[Option[ZonedDateTime]](prefix + "last_analyze"),
        lastAutoanalyze = row[Option[ZonedDateTime]](prefix + "last_autoanalyze"),
        vacuumCount = row[Option[Long]](prefix + "vacuum_count"),
        autovacuumCount = row[Option[Long]](prefix + "autovacuum_count"),
        analyzeCount = row[Option[Long]](prefix + "analyze_count"),
        autoanalyzeCount = row[Option[Long]](prefix + "autoanalyze_count")
      )
    )
  }

  implicit val oFormat: OFormat[PgStatSysTablesRow] = new OFormat[PgStatSysTablesRow]{
    override def writes(o: PgStatSysTablesRow): JsObject =
      Json.obj(
        "relid" -> o.relid,
      "schemaname" -> o.schemaname,
      "relname" -> o.relname,
      "seq_scan" -> o.seqScan,
      "seq_tup_read" -> o.seqTupRead,
      "idx_scan" -> o.idxScan,
      "idx_tup_fetch" -> o.idxTupFetch,
      "n_tup_ins" -> o.nTupIns,
      "n_tup_upd" -> o.nTupUpd,
      "n_tup_del" -> o.nTupDel,
      "n_tup_hot_upd" -> o.nTupHotUpd,
      "n_live_tup" -> o.nLiveTup,
      "n_dead_tup" -> o.nDeadTup,
      "n_mod_since_analyze" -> o.nModSinceAnalyze,
      "n_ins_since_vacuum" -> o.nInsSinceVacuum,
      "last_vacuum" -> o.lastVacuum,
      "last_autovacuum" -> o.lastAutovacuum,
      "last_analyze" -> o.lastAnalyze,
      "last_autoanalyze" -> o.lastAutoanalyze,
      "vacuum_count" -> o.vacuumCount,
      "autovacuum_count" -> o.autovacuumCount,
      "analyze_count" -> o.analyzeCount,
      "autoanalyze_count" -> o.autoanalyzeCount
      )

    override def reads(json: JsValue): JsResult[PgStatSysTablesRow] = {
      JsResult.fromTry(
        Try(
          PgStatSysTablesRow(
            relid = json.\("relid").toOption.map(_.as[/* oid */ Long]),
            schemaname = json.\("schemaname").toOption.map(_.as[String]),
            relname = json.\("relname").toOption.map(_.as[String]),
            seqScan = json.\("seq_scan").toOption.map(_.as[Long]),
            seqTupRead = json.\("seq_tup_read").toOption.map(_.as[Long]),
            idxScan = json.\("idx_scan").toOption.map(_.as[Long]),
            idxTupFetch = json.\("idx_tup_fetch").toOption.map(_.as[Long]),
            nTupIns = json.\("n_tup_ins").toOption.map(_.as[Long]),
            nTupUpd = json.\("n_tup_upd").toOption.map(_.as[Long]),
            nTupDel = json.\("n_tup_del").toOption.map(_.as[Long]),
            nTupHotUpd = json.\("n_tup_hot_upd").toOption.map(_.as[Long]),
            nLiveTup = json.\("n_live_tup").toOption.map(_.as[Long]),
            nDeadTup = json.\("n_dead_tup").toOption.map(_.as[Long]),
            nModSinceAnalyze = json.\("n_mod_since_analyze").toOption.map(_.as[Long]),
            nInsSinceVacuum = json.\("n_ins_since_vacuum").toOption.map(_.as[Long]),
            lastVacuum = json.\("last_vacuum").toOption.map(_.as[ZonedDateTime]),
            lastAutovacuum = json.\("last_autovacuum").toOption.map(_.as[ZonedDateTime]),
            lastAnalyze = json.\("last_analyze").toOption.map(_.as[ZonedDateTime]),
            lastAutoanalyze = json.\("last_autoanalyze").toOption.map(_.as[ZonedDateTime]),
            vacuumCount = json.\("vacuum_count").toOption.map(_.as[Long]),
            autovacuumCount = json.\("autovacuum_count").toOption.map(_.as[Long]),
            analyzeCount = json.\("analyze_count").toOption.map(_.as[Long]),
            autoanalyzeCount = json.\("autoanalyze_count").toOption.map(_.as[Long])
          )
        )
      )
    }
  }
}
